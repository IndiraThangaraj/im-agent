{
  "name": "im_agent",
  "nodes": [
    {
      "parameters": {
        "fileSelector": "/knowledge_base/*.pdf",
        "options": {}
      },
      "type": "n8n-nodes-base.readWriteFile",
      "typeVersion": 1,
      "position": [
        400,
        112
      ],
      "id": "7258de9e-288b-4ac2-b3d8-3aebae9ac3c1",
      "name": "Read/Write Files from Disk"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [
        144,
        112
      ],
      "id": "6bce8419-0e15-40f9-a49d-4b23503a3849",
      "name": "When clicking ‘Execute workflow’"
    },
    {
      "parameters": {
        "dataType": "binary",
        "binaryMode": "specificField",
        "loader": "pdfLoader",
        "options": {}
      },
      "id": "c3427a5b-6c30-4ec1-8c7a-a875fc08f39b",
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "position": [
        928,
        320
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "chunkOverlap": 100,
        "options": {
          "splitCode": "markdown"
        }
      },
      "id": "59ac9a35-91a8-4e92-a81a-3d5c743a1fde",
      "name": "Recursive Character Text Splitter",
      "type": "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter",
      "position": [
        960,
        480
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "content": "## Vector Store",
        "height": 680,
        "width": 1240,
        "color": 7
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        0,
        0
      ],
      "typeVersion": 1,
      "id": "2853ef9b-3083-411c-bfbd-1fdf47efc28e",
      "name": "Sticky Note"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "= {{ $json.body.email_content }}",
        "messages": {
          "messageValues": [
            {
              "message": "=You are an AI assistant tasked with processing email content for an incident management workflow. Your primary goal is to first identify the presence of data fields within {{ $json.body.email_content }}, ensuring they consolidated together provided if they are found. Finally, you will validate the data has been filled.  Here's the process:  Identify the following fields (if present) from {{ $json.body.email_content }}. \n\nAll identified fields must be consolidated together in this manner/template:  \"Username\" \"Card Number\" \"Access Number\" \"GCIF Number\" \"IC Number\" \"Date and Timestamp of Issue Happened\" \"Problem Statement\" \"Number of impacted customer\" \"Steps to reproduce the issue\" (including all numbered steps that follow it)  Validate the identified information: Check if all of them were successfully identified and is not an empty field.  \n\nIf ALL of the listed fields were identified, and contain any content (as per the validation rule above), provide {{ $json.body.email_content }} as the ONLY output, don't give any other information.  \n\nIf ANY of the listed fields were empty, output ONLY the exact phrase: \"Please follow the SFU Email template. [Refer this page: https://confluence.maybank.com.my/x/mYpTDQ]\" and give reason why it is incomplete (Information provided does not follow the template manner or missing information or etc. Give the output in HTML markdown"
            }
          ]
        },
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        144,
        960
      ],
      "id": "b2337623-a69b-411a-995e-4858b22bfe03",
      "name": "Basic LLM Chain"
    },
    {
      "parameters": {
        "rules": {
          "values": [
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "leftValue": "={{ $json.text }}",
                    "rightValue": "Please follow the SFU Email template.",
                    "operator": {
                      "type": "string",
                      "operation": "contains"
                    },
                    "id": "41f5e547-f5a1-40e9-b39b-fb792ce1cad5"
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "Reject"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "39704c03-0e80-45eb-948c-c722ec008180",
                    "leftValue": "={{ $json.text }}",
                    "rightValue": "Please follow the SFU Email template.",
                    "operator": {
                      "type": "string",
                      "operation": "notContains"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "Approve"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.switch",
      "typeVersion": 3.2,
      "position": [
        512,
        960
      ],
      "id": "84020be9-9e48-43b9-a11a-f114907992be",
      "name": "Switch"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "= {{ $json.text }}",
        "options": {
          "systemMessage": "You are a helpful AI support agent. Your task is to create a Root Cause Analysis (RCA) report based on the user's issue.\n\n**Tool Usage Rules:**\n1.  You MUST use the \"SOP Vector Store\" tool to fetch relevant Standard Operating Procedures (SOPs) from the SOP Vector Store based on the user's issue.\n2.  You MUST call this tool **only once**.\n3.  After the first tool call, you MUST stop using tools and synthesize your full response, even if the tool returns no data.\n\n**Report Generation Rules:**\n1.  Analyze the user's issue (from the input) AND the documents retrieved from the \"Postgres\" tool.\n2.  If the tool returns no relevant documents (i.e., the tool output is empty), you must still generate the report. For the \"Resolution\" section, write \"No resolution found in SOPs.\" For the \"Recommended Action\" section, you MUST write: \"Add SOP in the Knowledge Base so it can lessen the time to resolve this issue in the future.\"\n3.  If the tool *does* return relevant documents, you MUST use them to fill out the \"Resolution\" and \"Recommended Action\" sections. The \"Recommended Action\" should be the solution, troubleshooting, or debug steps found in the documents.\n\n**Output Format:**\nYou MUST generate the report in this exact HTML markdown format:\n\n<ul>\n    <li><b>Ticket Number:</b> [Infer from user issue or write TBD]</li>\n    <li><b>Customer:</b> [Infer from user issue or write TBD]</li>\n    <li><b>Issue Summary:</b> [Summarize the user's issue]</li>\n    <li><b>Timeline and Analysis:</b> [Analyze the user's issue based on the provided text]</li>\n    <li><b>Root Cause:</b> [Infer the root cause based on the issue and any SOP data]</li>\n    <li><b>Resolution:</b> [Follow Rule #2 or #3 above]</li>\n    <li><b>Recommended Action:</b> [Follow Rule #2 or #3 above]</li>\n</ul>",
          "maxIterations": 15
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.8,
      "position": [
        960,
        864
      ],
      "id": "1192b9f6-7cb4-4e25-9fbc-3b43c1bbf8fb",
      "name": "AI Agent"
    },
    {
      "parameters": {
        "content": "## L1: UNDERSTAND",
        "height": 800,
        "width": 740,
        "color": 3
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        912,
        752
      ],
      "typeVersion": 1,
      "id": "22de7c0a-4b3c-408b-95a4-c2c8c76e5c19",
      "name": "Sticky Note1"
    },
    {
      "parameters": {
        "content": "## PRE-ASSESSMENT\n### Making sure SFU sends email using the template provide",
        "height": 800,
        "width": 1580,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -672,
        752
      ],
      "typeVersion": 1,
      "id": "1ee46d71-c217-4b26-b9a4-15e4f81e7693",
      "name": "Sticky Note2"
    },
    {
      "parameters": {
        "content": "This is the data ingestion pipeline. The pdf docs with the SOP will be uploaded from the localhost and will be vectorized using Postgres Vector Store."
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        96,
        464
      ],
      "typeVersion": 1,
      "id": "fab5b685-e0a9-4dda-aa03-71bf1ea67642",
      "name": "Sticky Note3"
    },
    {
      "parameters": {
        "content": "When a mail comes to the issue management team, the gmail trigger sends all the content of the email to the next node."
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -384,
        1120
      ],
      "typeVersion": 1,
      "id": "c0a608cc-ee22-449d-bb36-39e7f31fa958",
      "name": "Sticky Note4"
    },
    {
      "parameters": {
        "content": "The pre-assesment will happen to validate the input received from each issue sent."
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        128,
        784
      ],
      "typeVersion": 1,
      "id": "a0f5d367-2401-4fef-b8b8-e2b0348f2f9b",
      "name": "Sticky Note5"
    },
    {
      "parameters": {
        "content": "If all the input/information are present it will be sent to the next node. Else, a email saying missing data will be sent."
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        144,
        1328
      ],
      "typeVersion": 1,
      "id": "0851820b-976c-4fed-b981-70994e95d0c8",
      "name": "Sticky Note6"
    },
    {
      "parameters": {
        "content": "This AI Agent, analysis the issue and performs a root cause analysis by referring to the SOP in the vector store. The agent later generates a detailed report on the root cause analysis and suggest SOP to handle that issue if the SOP is available. If the SOP is not available, the agent advise to add the related SOP. ",
        "width": 336
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1216,
        768
      ],
      "typeVersion": 1,
      "id": "ef78984d-cceb-45a6-bbc6-24db0e912f30",
      "name": "Sticky Note7"
    },
    {
      "parameters": {
        "content": "Later the analysis, SOP or advice is sent to the team via email."
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1392,
        1136
      ],
      "typeVersion": 1,
      "id": "c9edc1a5-ae49-44d2-b722-e23924b3cddf",
      "name": "Sticky Note8"
    },
    {
      "parameters": {
        "mode": "insert",
        "tableName": "table1",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.vectorStorePGVector",
      "typeVersion": 1.2,
      "position": [
        800,
        128
      ],
      "id": "a43ca81f-a165-452e-a5d2-e2ecb52a5e97",
      "name": "Postgres PGVector Store",
      "credentials": {
        "postgres": {
          "id": "uzxeTfdaoy23r3Zw",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "model": "/Users/00143773indiraapthangaraj/Documents/IM_AI/my_models/bge-m3-Q5_K_M.gguf",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "typeVersion": 1.2,
      "position": [
        784,
        320
      ],
      "id": "e9cf8cb2-35bd-4470-9669-25e347389f41",
      "name": "Embeddings OpenAI",
      "credentials": {
        "openAiApi": {
          "id": "jjD1KBxibAYrnwq0",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "/Users/00143773indiraapthangaraj/Documents/IM_AI/my_models/Mistral-7B-Instruct-v0.3.Q4_K_S.gguf",
          "mode": "list"
        },
        "options": {
          "temperature": 0
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        528,
        1328
      ],
      "id": "78f1123a-2c50-40a0-bd90-4802f26ab33d",
      "name": "OpenAI Chat Model1",
      "credentials": {
        "openAiApi": {
          "id": "3J7NrTq8U3za4aqE",
          "name": "OpenAi account 2"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "typeVersion": 1.2,
      "position": [
        1088,
        1408
      ],
      "id": "453b539a-3220-4c2d-a1ae-0d37d4fdf1ff",
      "name": "Embeddings OpenAI2",
      "credentials": {
        "openAiApi": {
          "id": "jjD1KBxibAYrnwq0",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "baa9beec-862d-4c55-86c2-003f2830a2ab",
        "responseMode": "responseNode",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2.1,
      "position": [
        -256,
        960
      ],
      "id": "44d0383e-82bb-4bcf-b90e-f7b4a0345d33",
      "name": "Webhook",
      "webhookId": "baa9beec-862d-4c55-86c2-003f2830a2ab"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.4,
      "position": [
        1296,
        992
      ],
      "id": "f51a1e32-e22e-44bf-bc16-24c906c3c91c",
      "name": "Respond to Webhook"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.4,
      "position": [
        720,
        768
      ],
      "id": "f6168040-a7af-413e-a6b0-dea9a29b34b5",
      "name": "Respond to Webhook1"
    },
    {
      "parameters": {
        "mode": "retrieve-as-tool",
        "toolDescription": "Please use this tool to ",
        "tableName": "table1",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.vectorStorePGVector",
      "typeVersion": 1.3,
      "position": [
        1056,
        1184
      ],
      "id": "3deb2bf0-76a0-4cc2-8d46-35a5b6474aa1",
      "name": "SOP Vector store",
      "credentials": {
        "postgres": {
          "id": "uzxeTfdaoy23r3Zw",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolThink",
      "typeVersion": 1.1,
      "position": [
        944,
        1200
      ],
      "id": "119848b0-47f5-4114-95b7-27743dbd1a91",
      "name": "Think"
    }
  ],
  "pinData": {},
  "connections": {
    "Read/Write Files from Disk": {
      "main": [
        [
          {
            "node": "Postgres PGVector Store",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "When clicking ‘Execute workflow’": {
      "main": [
        [
          {
            "node": "Read/Write Files from Disk",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Default Data Loader": {
      "ai_document": [
        [
          {
            "node": "Postgres PGVector Store",
            "type": "ai_document",
            "index": 0
          }
        ]
      ]
    },
    "Recursive Character Text Splitter": {
      "ai_textSplitter": [
        [
          {
            "node": "Default Data Loader",
            "type": "ai_textSplitter",
            "index": 0
          }
        ]
      ]
    },
    "Basic LLM Chain": {
      "main": [
        [
          {
            "node": "Switch",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Switch": {
      "main": [
        [
          {
            "node": "Respond to Webhook1",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings OpenAI": {
      "ai_embedding": [
        [
          {
            "node": "Postgres PGVector Store",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain",
            "type": "ai_languageModel",
            "index": 0
          },
          {
            "node": "AI Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings OpenAI2": {
      "ai_embedding": [
        [
          {
            "node": "SOP Vector store",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "Webhook": {
      "main": [
        [
          {
            "node": "Basic LLM Chain",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "AI Agent": {
      "main": [
        [
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "SOP Vector store": {
      "ai_tool": [
        [
          {
            "node": "AI Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Think": {
      "ai_tool": [
        [
          {
            "node": "AI Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": true,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "d51dc649-61d4-4c47-97b2-df2b9f5793d0",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "e1f809eab203b3cdb65ffb4c5e6ea471210f3097e9bec325ecb8eabf0dadf97e"
  },
  "id": "YiHROqqIfEaFs3VC",
  "tags": []
}